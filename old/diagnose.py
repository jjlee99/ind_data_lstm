#!/usr/bin/env python3
"""
CUDA í™˜ê²½ ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸
PyTorchì—ì„œ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì œë¥¼ ì§„ë‹¨í•©ë‹ˆë‹¤.
"""

import os
import subprocess
import sys

def run_command(cmd):
    """ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜"""
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        return result.stdout.strip(), result.stderr.strip(), result.returncode
    except Exception as e:
        return "", str(e), -1

def check_nvidia_driver():
    """NVIDIA ë“œë¼ì´ë²„ í™•ì¸"""
    print("=== 1. NVIDIA ë“œë¼ì´ë²„ í™•ì¸ ===")
    stdout, stderr, code = run_command("nvidia-smi --query-gpu=driver_version --format=csv,noheader")
    if code == 0:
        print(f"âœ… NVIDIA ë“œë¼ì´ë²„: {stdout}")
    else:
        print(f"âŒ nvidia-smi ì‹¤í–‰ ì‹¤íŒ¨: {stderr}")
    print()

def check_cuda_installation():
    """CUDA ì„¤ì¹˜ í™•ì¸"""
    print("=== 2. CUDA ì„¤ì¹˜ í™•ì¸ ===")
    
    # nvcc í™•ì¸
    stdout, stderr, code = run_command("nvcc --version")
    if code == 0:
        print("âœ… nvcc ì‚¬ìš© ê°€ëŠ¥")
        version_line = [line for line in stdout.split('\n') if 'release' in line.lower()]
        if version_line:
            print(f"â†’ {version_line[0].strip()}")
    else:
        print("âŒ nvcc ì‚¬ìš© ë¶ˆê°€ (CUDA toolkit ë¯¸ì„¤ì¹˜ ë˜ëŠ” PATH ë¬¸ì œ)")
    
    # CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ í™•ì¸
    cuda_paths = [
        "/usr/local/cuda",
        "/usr/local/cuda-12.8",
        "/usr/local/cuda-12",
        "/opt/cuda"
    ]
    
    print("\nâ†’ CUDA ì„¤ì¹˜ ê²½ë¡œ í™•ì¸:")
    for path in cuda_paths:
        if os.path.exists(path):
            print(f"  âœ… {path}")
        else:
            print(f"  âŒ {path}")
    print()

def check_environment_variables():
    """í™˜ê²½ ë³€ìˆ˜ í™•ì¸"""
    print("=== 3. í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ===")
    
    env_vars = [
        "CUDA_HOME",
        "CUDA_ROOT",
        "CUDA_PATH",
        "PATH",
        "LD_LIBRARY_PATH",
        "CUDA_VISIBLE_DEVICES"
    ]
    
    for var in env_vars:
        value = os.environ.get(var, "ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        if var == "PATH":
            # PATHì—ì„œ CUDA ê´€ë ¨ ê²½ë¡œë§Œ ì¶”ì¶œ
            cuda_paths = [p for p in value.split(':') if 'cuda' in p.lower()]
            if cuda_paths:
                print(f"â†’ {var} (CUDA ê´€ë ¨): {':'.join(cuda_paths)}")
            else:
                print(f"â†’ {var}: CUDA ê´€ë ¨ ê²½ë¡œ ì—†ìŒ")
        elif var == "LD_LIBRARY_PATH":
            if value != "ì„¤ì •ë˜ì§€ ì•ŠìŒ":
                cuda_paths = [p for p in value.split(':') if 'cuda' in p.lower()]
                if cuda_paths:
                    print(f"â†’ {var} (CUDA ê´€ë ¨): {':'.join(cuda_paths)}")
                else:
                    print(f"â†’ {var}: CUDA ê´€ë ¨ ê²½ë¡œ ì—†ìŒ")
            else:
                print(f"â†’ {var}: {value}")
        else:
            print(f"â†’ {var}: {value}")
    print()

def check_pytorch_installation():
    """PyTorch ì„¤ì¹˜ í™•ì¸"""
    print("=== 4. PyTorch ì„¤ì¹˜ í™•ì¸ ===")
    
    try:
        import torch
        print(f"âœ… PyTorch ë²„ì „: {torch.__version__}")
        print(f"â†’ CUDA ë¹Œë“œ ë²„ì „: {torch.version.cuda}")
        print(f"â†’ cuDNN ë²„ì „: {torch.backends.cudnn.version()}")
        
        # CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ (ê²½ê³  ë©”ì‹œì§€ í¬í•¨)
        print("\nâ†’ CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í…ŒìŠ¤íŠ¸:")
        cuda_available = torch.cuda.is_available()
        print(f"  torch.cuda.is_available(): {cuda_available}")
        
        if cuda_available:
            print(f"  ì¥ì¹˜ ìˆ˜: {torch.cuda.device_count()}")
            print(f"  í˜„ì¬ ì¥ì¹˜: {torch.cuda.current_device()}")
            print(f"  ì¥ì¹˜ ì´ë¦„: {torch.cuda.get_device_name(0)}")
        
    except ImportError:
        print("âŒ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
    except Exception as e:
        print(f"âŒ PyTorch í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
    print()

def check_cuda_libraries():
    """CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸"""
    print("=== 5. CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ ===")
    
    libraries = [
        "libcuda.so",
        "libcublas.so",
        "libcurand.so",
        "libcusparse.so"
    ]
    
    for lib in libraries:
        stdout, stderr, code = run_command(f"ldconfig -p | grep {lib}")
        if code == 0 and stdout:
            print(f"âœ… {lib} ë°œê²¬")
            # ì²« ë²ˆì§¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œë§Œ í‘œì‹œ
            first_lib = stdout.split('\n')[0].split('=>')[-1].strip()
            print(f"  â†’ {first_lib}")
        else:
            print(f"âŒ {lib} ì—†ìŒ")
    print()

def main():
    """ë©”ì¸ ì§„ë‹¨ í•¨ìˆ˜"""
    print("ğŸ” CUDA í™˜ê²½ ì§„ë‹¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")
    
    check_nvidia_driver()
    check_cuda_installation()
    check_environment_variables()
    check_pytorch_installation()
    check_cuda_libraries()
    
    print("=== ì§„ë‹¨ ì™„ë£Œ ===")
    print("ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("\nì£¼ìš” í•´ê²° ë°©ë²•:")
    print("1. CUDA Toolkit ì„¤ì¹˜ í™•ì¸")
    print("2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (CUDA_HOME, PATH, LD_LIBRARY_PATH)")
    print("3. PyTorch ì¬ì„¤ì¹˜ (ì˜¬ë°”ë¥¸ CUDA ë²„ì „)")
    print("4. ì‹œìŠ¤í…œ ì¬ë¶€íŒ…")

if __name__ == "__main__":
    main()